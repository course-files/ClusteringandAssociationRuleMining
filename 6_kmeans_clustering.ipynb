{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c25de96",
   "metadata": {},
   "source": [
    "# Clustering using the k-Means Clustering Algorithm\n",
    "\n",
    "| Key              | Value                                                                                                                                                                                                                                                                                                        |\n",
    "|:-----------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Course Codes** | BBT 4206 and BFS 4102                                                                                                                                                                                                                                                                                        |\n",
    "| **Course Names** | BBT 4206: Business Intelligence II (Week 1-3 of 13) and<br/>BFS 4102: Advanced Business Data Analytics (Week 4-6 of 13)                                                                                                                                                                                      |\n",
    "| **Semester**     | August to November 2025                                                                                                                                                                                                                                                                                      |\n",
    "| **Lecturer**     | Allan Omondi                                                                                                                                                                                                                                                                                                 |\n",
    "| **Contact**      | aomondi@strathmore.edu                                                                                                                                                                                                                                                                                       |\n",
    "| **Note**         | The lecture contains both theory and practice.<br/>This notebook forms part of the practice.<br/>It is intended for educational purposes only.<br/>Recommended citation: [BibTex](https://raw.githubusercontent.com/course-files/ClusteringandAssociationRuleMining/refs/heads/main/RecommendedCitation.bib) |\n",
    "\n",
    "**Business context**: A business aims to refine its marketing strategy by grouping customers into distinct segments based on _demographic details_ and _spending behavior_. This segmentation strategy serves as a foundation for implementing highly personalized marketing campaigns, where the leading KPI is the _customer engagement with tailored adverts_, and the lagging KPI is the _increase in overall customer spending_. By identifying specific customer clusters, the marketing team can optimize advertising efforts to target each group more effectively, ultimately driving increased customer satisfaction and revenue.\n",
    "\n",
    "**Dataset**: The dataset used is based on the **\"Mall Customers\"** dataset, which consists of 200 observations. Each observation represents a customer, and the dataset includes demographic and behavioral features that are essential for customer segmentation.\n",
    "\n",
    "| **Feature Type** | **Feature Name**         | **Description**                                                                              |\n",
    "|:-----------------|:-------------------------|:---------------------------------------------------------------------------------------------|\n",
    "| **Feature**      | `CustomerID`             | A unique identifier assigned to each customer                                                |\n",
    "| **Feature**      | `Genre`                  | Gender of the customer (Male or Female)                                                      |\n",
    "| **Feature**      | `Age`                    | Age of the customer in years                                                                 |\n",
    "| **Feature**      | `Annual Income (k$)`     | Annual income of the customer in thousands of dollars                                        |\n",
    "| **Feature**      | `Spending Score (1-100)` | Spending behavior of the customer on a scale of 1 to 100, with 100 being the highest spender |\n",
    "\n",
    "Suppose that the dataset has been provided by the organization's customer service department for clustering purposes. This is done to segment customers into distinct groups based on their demographics (`Age`, `Genre`) and spending behaviors (`Annual Income`, `Spending Score`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab31c384d3c41f",
   "metadata": {},
   "source": [
    "`import pandas as pd`\n",
    "- 'Pandas' is essential because it is used for:\n",
    "    - Loading the CSV data (`pd.read_csv()`)\n",
    "    - Data manipulation and analysis\n",
    "    - Creating and managing DataFrames\n",
    "    - Essential for structured data analysis, e.g., `Group By` operations\n",
    "\n",
    "`import matplotlib.pyplot as plt`\n",
    "- 'Matplotlib' is used for:\n",
    "    - Visualising data\n",
    "    - Plotting graphs (e.g., scatter plots, line plots, the elbow method graph)\n",
    "    - Customising visualisations (labels, titles, legends)\n",
    "\n",
    "`from sklearn.preprocessing import StandardScaler, MinMaxScaler`\n",
    "- 'StandardScaler' is used for:\n",
    "    - Scaling features to have a mean of 0 and standard deviation of 1\n",
    "    - This **data transformation** (referred to as standardization) is necessary to ensure that all features contribute equally to the distance calculations when clustering\n",
    "- 'MinMaxScaler' is used for:\n",
    "    - Normalization to ensure numeric features range between 0 and 1\n",
    "- One-Hot encoding is another data transformation technique that converts categorical variables into binary vectors. It is not applied in this case\n",
    "\n",
    "`from sklearn.cluster import KMeans`\n",
    "- 'KMeans' is used for:\n",
    "    - Performing K-Means clustering\n",
    "    - Finding clusters in the data based on the features provided\n",
    "    - The `fit_predict()` method can then be used to fit the model and predict cluster labels for each data point\n",
    "\n",
    "`import seaborn as sns`\n",
    "- 'Seaborn' is used for:\n",
    "    - Enhanced data visualisation\n",
    "    - Creating more aesthetically pleasing and informative plots (e.g., histograms, box plots, heatmaps)\n",
    "    - It provides a high-level interface for drawing attractive statistical graphics\n",
    "\n",
    "`import warnings`\n",
    "`warnings.filterwarnings('ignore')`\n",
    "- 'Warnings' is used to suppress warnings that may arise during the execution of the code, such as convergence warnings from K-Means. Even though it is not necessary for the clustering, it helps keep the output clean and focused on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436828996c931f4f",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For file and system operations\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# For data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For statistical data analysis\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "# For data preprocessing and transformation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# For Machine Learning\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For model persistence\n",
    "import joblib\n",
    "\n",
    "# For suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "629acd83e7aa02b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cab57e2b",
   "metadata": {},
   "source": [
    "## Step 2: Load the data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_path = './data/mall_customers.csv'\n",
    "url = 'https://raw.githubusercontent.com/course-files/ClusteringandAssociationRuleMining/refs/heads/main/data/mall_customers.csv'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    if not os.path.exists('./data'):\n",
    "        os.makedirs('./data')\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "    print(\"✅ Dataset downloaded\")\n",
    "else:\n",
    "    print(\"✅ Dataset already exists locally\")\n",
    "\n",
    "use_cols = ['CustomerID', 'Genre', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n",
    "customer_data = pd.read_csv(dataset_path, usecols=use_cols, encoding='utf-8', nrows=200000)"
   ],
   "id": "8284dace0129e1bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Identify the numeric and categorical columns",
   "id": "47bec177e9105ceb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Selection of numeric columns**\n",
    "- The code identifies columns with numeric data types (`int64` and `float64`) that can be subjected to mathematical or statistical functions.\n",
    "- The code also identifies non-numeric columns (e.g., `strings`, `objects`, etc.) by excluding numeric (`int64`, `float64`) and `datetime` data types.\n",
    "- This is done using `select_dtypes()` method of the DataFrame, which filters columns based on their data types."
   ],
   "id": "53241ff14ab17a4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_cols = customer_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = customer_data.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]']).columns\n",
    "\n",
    "print(\"\\nThe identified numeric columns are:\")\n",
    "print(numeric_cols.tolist())\n",
    "\n",
    "print(\"\\nThe identified categorical columns is/are:\")\n",
    "print(categorical_cols.tolist())"
   ],
   "id": "64da2b69efc3b2b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14af1ac2",
   "metadata": {},
   "source": [
    "## Step 3: Initial Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n*1* The number of observations and variables\")\n",
    "display(customer_data.shape)\n",
    "\n",
    "print(\"\\n*2* The data types:\")\n",
    "display(customer_data.info())\n",
    "\n",
    "print(\"\\n*3* The summary of the numeric columns:\")\n",
    "display(customer_data.describe())\n",
    "\n",
    "print(\"\\n*4* The whole dataset:\")\n",
    "display(customer_data)\n",
    "\n",
    "print(\"\\n*5* The first 5 rows in the dataset:\")\n",
    "display(customer_data.head())\n",
    "\n",
    "print(\"\\n*6* Percentage distribution for each category\")\n",
    "print(\"\\nNumber of observations per class:\")\n",
    "print(\"Frequency counts:\\n\", customer_data['Genre'].value_counts())\n",
    "print(\"\\nPercentages:\\n\", customer_data['Genre'].value_counts(normalize=True) * 100, \"%\")"
   ],
   "id": "d706ff914bf55399",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7abbd99b33725ec7",
   "metadata": {},
   "source": "### Measures of Distribution"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Variance of numeric columns",
   "id": "407f86981d21d911"
  },
  {
   "cell_type": "code",
   "id": "bcdc6609026baf06",
   "metadata": {},
   "source": [
    "print(\"\\nVariance of numeric columns:\")\n",
    "print(customer_data[numeric_cols].var())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a9a9ed6d21e5dab7",
   "metadata": {},
   "source": [
    "#### Standard deviation of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "57cbbe7a",
   "metadata": {},
   "source": [
    "print(\"\\nStandard deviation of numeric columns:\")\n",
    "print(customer_data[numeric_cols].std())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f0af4a31ac703ebc",
   "metadata": {},
   "source": [
    "#### Kurtosis of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c7208515de4ed4f",
   "metadata": {},
   "source": [
    "print(\"\\nFisher Kurtosis of numeric columns:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive kurtosis indicates heavier tails (more outliers) than what is expected in a normal distribution - leptokurtic\")\n",
    "print(\"→ Negative kurtosis indicates lighter tails (less outliers) than what is expected in a normal distribution - platykurtic\")\n",
    "print(\"→ A normal distribution has kurtosis of 0 - mesokurtic\")\n",
    "print(\"\\nKurtosis values:\")\n",
    "print(customer_data[numeric_cols].apply(lambda x: kurtosis(x, fisher=True)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "227f735f0d994f13",
   "metadata": {},
   "source": [
    "#### Skewness of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "2852ec3f452a6528",
   "metadata": {},
   "source": [
    "print(\"\\nSkewness of numeric columns:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive skewness indicates a long right tail (right-skewed distribution)\")\n",
    "print(\"→ Negative skewness indicates a long left tail (left-skewed distribution)\")\n",
    "print(\"→ Skewness close to 0 indicates a symmetric distribution\")\n",
    "print(\"\\nSkewness values:\")\n",
    "print(customer_data[numeric_cols].apply(lambda x: skew(x)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "204ee308e5be312f",
   "metadata": {},
   "source": [
    "### Measures of Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715c9be50b541a1",
   "metadata": {},
   "source": [
    "#### Covariance matrix of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3f439586764d6bb",
   "metadata": {},
   "source": [
    "print(\"\\nCovariance matrix of numeric features:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive values indicate that variables move in the same direction\")\n",
    "print(\"→ Negative values indicate that variables move in opposite directions\")\n",
    "print(\"→ Values close to 0 indicate little to no linear relationship\")\n",
    "print(\"\\nCovariance values:\")\n",
    "display(customer_data[numeric_cols].cov())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ec5670a510471389",
   "metadata": {},
   "source": [
    "#### Correlation matrix of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "id": "996b88415671be22",
   "metadata": {},
   "source": [
    "print(\"\\nSpearman correlation matrix of numeric features:\")\n",
    "spearman_corr = customer_data[numeric_cols].corr(method='spearman')\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Values range from -1 to +1\")\n",
    "print(\"→ +1 indicates perfect positive correlation\")\n",
    "print(\"→ -1 indicates perfect negative correlation\")\n",
    "print(\"→ 0 indicates no correlation\")\n",
    "print(\"\\nCorrelation values:\")\n",
    "display(spearman_corr)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6ac9fb47c28a6a91",
   "metadata": {},
   "source": [
    "### Basic visualization of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a71263aa93fd59",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "id": "26c36e5d190247fd",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(1, len(numeric_cols), i)\n",
    "    sns.histplot(data=customer_data, x=col)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5852b490dd3ba63c",
   "metadata": {},
   "source": [
    "#### Box plots"
   ]
  },
  {
   "cell_type": "code",
   "id": "60f2d02aeca334c8",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(1, len(numeric_cols), i)\n",
    "    sns.boxplot(data=customer_data, y=col)\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6b0747a28b475e3",
   "metadata": {},
   "source": [
    "#### Missing data plot"
   ]
  },
  {
   "cell_type": "code",
   "id": "828eb440fdc9c7e8",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(customer_data.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "plt.title('Missing Data')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a6cb829a87597c6",
   "metadata": {},
   "source": [
    "#### Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "id": "47acf861b8cc57a2",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c6a725bd04e1e223",
   "metadata": {},
   "source": [
    "#### Scatter plot matrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "29e527064be05b5f",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.pairplot(customer_data[['CustomerID', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)']])\n",
    "plt.suptitle('Scatter Plot Matrix', y=1.02)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4ebf6d861209217a",
   "metadata": {},
   "source": [
    "## Step 4: Feature selection for clustering\n",
    "We will use **Age**, **Annual Income (KES)**, and **Spending Score (1‑100)**."
   ]
  },
  {
   "cell_type": "code",
   "id": "e6d19d51",
   "metadata": {},
   "source": [
    "X = customer_data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']].copy()\n",
    "X.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "73ddfbb7",
   "metadata": {},
   "source": [
    "## Step 5: Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "id": "359eb0eb",
   "metadata": {},
   "source": [
    "# Option 1: Standardize (mean=0, variance=1)\n",
    "scaler_standard = StandardScaler()\n",
    "X_scaled = scaler_standard.fit_transform(X)\n",
    "print(\"\\nStandardized data (mean=0, variance=1):\")\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(X_scaled_df.head())\n",
    "print(\"\\nMean and standard deviation:\")\n",
    "display(X_scaled_df.describe())\n",
    "\n",
    "\n",
    "# Option 2: Normalize (scale between 0 and 1) - this is optional for k-Means\n",
    "# normalizer = MinMaxScaler()\n",
    "# X_normalized = normalizer.fit_transform(X)\n",
    "# print(\"\\nNormalized data (scale between 0 and 1):\")\n",
    "# print(X_normalized)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "015b0887",
   "metadata": {},
   "source": [
    "## Step 6: Determine the optimal number of clusters using the Elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00219eaa2f2091",
   "metadata": {},
   "source": [
    "1. **Inertia Calculation Loop:**\n",
    "   - Creates an empty list `inertia` to store the sum of squared distances\n",
    "   - Loops through k values from 1 to 10 using `range(1,11)`\n",
    "   - For each k value:\n",
    "     - Creates a KMeans model with k clusters\n",
    "     - Fits the model to the scaled data\n",
    "     - Adds the inertia (Within-Cluster Sum of Squares [WCSS]) to the list\n",
    "          - **Within-Cluster Sum of Squares (WCSS)**, also known as **inertia**, measures the compactness of clusters in a clustering algorithm. It represents the sum of the squared distances between each data point in a cluster and the centroid of that cluster. A lower WCSS indicates that the data points within each cluster are closer to their respective centroid, suggesting tighter, more compact clusters.\n",
    "\n",
    "2. **Visualization:**\n",
    "   - Creates a figure of size 6x4\n",
    "   - Plots k values (x-axis) against inertia values (y-axis)\n",
    "   - Adds markers 'o' at each point\n",
    "   - Labels axes and adds title\n",
    "   - Displays the plot\n",
    "\n",
    "3. **Purpose:**\n",
    "   - The Elbow Method helps in finding the optimal number of clusters\n",
    "   - The \"elbow\" in the plot indicates where adding more clusters gives diminishing returns\n",
    "   - Point where the line starts to level out suggests optimal k value"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb8c11f0",
   "metadata": {},
   "source": [
    "inertia = []\n",
    "K = range(1, 11)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=53)\n",
    "    km.fit(X_scaled)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(K, inertia, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "plt.title('Elbow Method for Finding the \\\"Optimal K\\\" in K-Means Clustering')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35f37ebd",
   "metadata": {},
   "source": [
    "Based on the elbow plot, **k = 5** gives the ideal number of clusters; where adding more clusters does not significantly improve tightness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031b82b5ed5cb7b",
   "metadata": {},
   "source": [
    "## Step 7: Apply K-Means clustering using the optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "id": "7253d302",
   "metadata": {},
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=53)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "customer_data['Cluster'] = clusters\n",
    "customer_data.head()\n",
    "customer_data.to_csv('./data/mall_customers_with_clusters.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8bbf6ee3",
   "metadata": {},
   "source": [
    "## Step 8: Visualize the clusters"
   ]
  },
  {
   "cell_type": "code",
   "id": "0ca777e6",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "scatter = plt.scatter(customer_data['Annual Income (k$)'],\n",
    "                      customer_data['Spending Score (1-100)'],\n",
    "                      c=customer_data['Cluster'], s=25)\n",
    "plt.xlabel('Annual Income')\n",
    "plt.ylabel('Spending Score (1‑100)')\n",
    "plt.title('Customer Segments by Spending Score and Annual Income')\n",
    "plt.legend(*scatter.legend_elements(), title='Cluster', loc='upper right',\n",
    "           bbox_to_anchor=(1.15, 1), fontsize='small')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3608b1429fd56321",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "scatter = plt.scatter(customer_data['Age'],\n",
    "                      customer_data['Spending Score (1-100)'],\n",
    "                      c=customer_data['Cluster'], s=25)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Spending Score (1‑100)')\n",
    "plt.title('Customer Segments by Spending Score and Age')\n",
    "plt.legend(*scatter.legend_elements(), title='Cluster', loc='upper right',\n",
    "           bbox_to_anchor=(1.15, 1), fontsize='small')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cb4566d3",
   "metadata": {},
   "source": [
    "## Step 9: Interpret the clusters (customer segments in the market)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6fc96a9157cfbd6",
   "metadata": {},
   "source": [
    "print(\"\\nGender distribution by cluster:\")\n",
    "print(pd.crosstab(customer_data['Cluster'], customer_data['Genre']))\n",
    "print(\"\\nCluster statistics:\")\n",
    "print(\"\\nMeans:\")\n",
    "display(customer_data.groupby('Cluster').mean(numeric_only=True))\n",
    "print(\"\\nStandard deviations:\")\n",
    "display(customer_data.groupby('Cluster').std(numeric_only=True))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "95f971ddbfe6e4ea",
   "metadata": {},
   "source": [
    "| Cluster | Typical age | Gender | Income level | Spending Behaviour |\n",
    "|---------|-------------|--------|--------------|--------------------|\n",
    "| 0       | Young       | Both   | High         | Targeted premium   |\n",
    "| 1       | Young       | Both   | Low–medium   | Average spenders   |\n",
    "| 2       | Mature      | Both   | High         | Low spenders       |\n",
    "| 3       | Mature      | Female | Low          | Frugal             |\n",
    "| 4       | Middle‑age  | Both   | Medium       | Luxury shoppers    |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lab Submission Requirements",
   "id": "1dcd8bd02fa33396"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Provide the code to download the `'./data/mall_customers_with_clusters.csv'` file, which contains the original dataset with an additional column for the cluster labels assigned by the K-Means algorithm. This code should work in Google Colab.\n",
    "2. Provide the code to train a Support Vector Machine (SVM) model using the `X` and `y` variables, where `X` is the feature matrix and `y` is the target variable (the cluster labels). The SVM model should be trained to predict the cluster labels based on the features.\n",
    "3. Provide the code to demonstrate the prediction of cluster labels using the trained SVM model. This should include a sample input and the predicted cluster label for that input.\n",
    "4. Submit the link to your notebook via the Google Form provided on Google Classroom. Ensure that you indicate your name and student ID in the notebook."
   ],
   "id": "fe74839eb57380d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
