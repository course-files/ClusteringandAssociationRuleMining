{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6707ab3f",
   "metadata": {},
   "source": [
    "# Association Rule Learning using the Apriori Algorithm\n",
    "\n",
    "| Key              | Value                                                                                                                                                                                                                                                                                                        |\n",
    "|:-----------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Course Codes** | BBT 4206 and BFS 4102                                                                                                                                                                                                                                                                                        |\n",
    "| **Course Names** | BBT 4206: Business Intelligence II (Week 1-3 of 13) and<br/>BFS 4102: Advanced Business Data Analytics (Week 4-6 of 13)                                                                                                                                                                                      |\n",
    "| **Semester**     | August to November 2025                                                                                                                                                                                                                                                                                      |\n",
    "| **Lecturer**     | Allan Omondi                                                                                                                                                                                                                                                                                                 |\n",
    "| **Contact**      | aomondi@strathmore.edu                                                                                                                                                                                                                                                                                       |\n",
    "| **Note**         | The lecture contains both theory and practice.<br/>This notebook forms part of the practice.<br/>It is intended for educational purposes only.<br/>Recommended citation: [BibTex](https://raw.githubusercontent.com/course-files/ClusteringandAssociationRuleMining/refs/heads/main/RecommendedCitation.bib) |\n",
    "\n",
    "**Business Context**: A supermarket chain seeks to uncover frequent item combinations from historical transactions to improve product placement, plan promotions, and increase cross-selling.\n",
    "\n",
    "**Dataset**: A synthetic dataset of transactions, where each transaction is a list of items purchased together."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 1: Import the necessary libraries",
   "id": "7581ebe5c7fc59cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Purpose**: This chunk imports all the necessary libraries for data analysis, machine learning, and visualization.\n",
    "\n",
    "1. **For data manipulation - [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html):**\n",
    "    - `pandas as pd`: For loading the dataset, creating and managing DataFrames, data manipulation and analysis using DataFrames\n",
    "\n",
    "2. **For data preprocessing and transformation - [mlxtend](https://rasbt.github.io/mlxtend/)**\n",
    "    - `TransactionEncoder`: Converts transaction data into a binary matrix format\n",
    "\n",
    "3. **For association rule learning - [mlxtend](https://rasbt.github.io/mlxtend/)**\n",
    "    - `apriori`: Implements the Apriori algorithm for finding frequent itemsets\n",
    "    - `association_rules`: Generates rules from frequent itemsets\n",
    "\n",
    "4. **For data visualization - [matplotlib](https://matplotlib.org/stable/gallery/index.html) and [seaborn](https://seaborn.pydata.org/examples/index.html)**\n",
    "    - `matplotlib.pyplot as plt`: For basic plotting functionality\n",
    "    - `seaborn as sns`: For enhanced statistical visualizations\n",
    "\n",
    "5. **For suppressing warnings - [warnings](https://docs.python.org/3/library/warnings.html)**\n",
    "    - `warnings`: Controls warning messages\n",
    "    - `warnings.filterwarnings('ignore')`: Suppresses warning messages for cleaner output\n",
    "    - Used to suppress warnings that may arise during the execution of the code. Even though it is not necessary for the code to run, it helps in keeping the output clean and focused on the results."
   ],
   "id": "462d352864ff9375"
  },
  {
   "cell_type": "code",
   "id": "7f7e4ec8",
   "metadata": {},
   "source": [
    "# For data manipulation\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# For data preprocessing and transformation\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# For Association Rule Learning\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6a5d5cc0",
   "metadata": {},
   "source": "## Step 2: Load the data"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. **Data Loading Process**\n",
    "    - Uses a context manager (`with` statement) for proper resource handling\n",
    "    - Steps:\n",
    "        1. Opens URL connection\n",
    "        2. Reads binary content\n",
    "        3. Decodes from bytes to UTF-8 string\n",
    "        4. Splits into lines and processes each line\n",
    "\n",
    "2. **Data Processing**\n",
    "    - List comprehension transforms raw data into a structured format\n",
    "    - Each transaction is processed by:\n",
    "        - `strip()`: Removes whitespace\n",
    "        - `split(',')`: Creates a list of items from comma-separated values\n",
    "\n",
    "3. **Output**\n",
    "    - Prints the total number of transactions\n",
    "    - Shows the first three transactions as a sample\n"
   ],
   "id": "e7796a6675a67683"
  },
  {
   "cell_type": "code",
   "id": "a2390adf",
   "metadata": {},
   "source": [
    "transactions = [\n",
    "    ['matoke', 'sukuma wiki', 'kienyeji chicken'],\n",
    "    ['matoke', 'beans', 'maziwa mala', 'ndizi'],\n",
    "    ['matoke', 'beans', 'maziwa mala', 'mango'],\n",
    "    ['maziwa mala', 'matoke', 'beans', 'ndizi'],\n",
    "    ['maziwa mala', 'matoke', 'beans', 'mango']\n",
    "]\n",
    "\n",
    "print(f\"Total number of transactions: {len(transactions)}\")\n",
    "print(\"\\nFirst three transactions:\")\n",
    "transactions[:3]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b6f5d2b1",
   "metadata": {},
   "source": "## Step 3: Convert the transaction list into a one-hot encoded DataFrame"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Purpose:**\n",
    "\n",
    "The purpose of this chunk is to format the transaction data correctly. This is essential for:\n",
    "- Running the Apriori algorithm\n",
    "- Computing association rules\n",
    "- Analyzing item frequencies and relationships\n",
    "\n",
    "1. **Transaction Encoder Initialization**\n",
    "    - Creates a new `TransactionEncoder` object called `encoder`\n",
    "    - Purpose: To convert transaction lists into a binary matrix format\n",
    "\n",
    "2. **Fit and Transform Process**\n",
    "    - `encoder.fit(transactions)`:\n",
    "        - Learns all unique items across all transactions\n",
    "        - Creates a mapping of items to columns\n",
    "\n",
    "    - `transform(transactions)`:\n",
    "        - Converts transactions into a binary matrix\n",
    "        - Each row represents one transaction\n",
    "        - Each column represents one item\n",
    "        - Values: True/False indicating item presence\n",
    "\n",
    "3. **DataFrame Creation**\n",
    "    - Converts the binary matrix into a `pandas` DataFrame\n",
    "    - Uses `encoder.columns_` to retrieve the column names\n",
    "    - Each column name is a unique item\n",
    "    - Each row shows items present (True) or absent (False)\n",
    "\n",
    "4. **Data Preview**\n",
    "    - `transaction_data.head()`: Shows first five rows of transformed data\n",
    "\n",
    "**Example:**\n",
    "If the original transactions were:\n",
    "```\n",
    "Transaction 1: [\"milk\", \"bread\"]\n",
    "Transaction 2: [\"bread\", \"butter\"]\n",
    "```\n",
    "The transformed data would look like this:\n",
    "```\n",
    "   milk  bread  butter\n",
    "0  True   True  False\n",
    "1  False  True   True\n",
    "```"
   ],
   "id": "eebaf02bf6039263"
  },
  {
   "cell_type": "code",
   "id": "dc60c753",
   "metadata": {},
   "source": [
    "encoder = TransactionEncoder()\n",
    "onehot = encoder.fit(transactions).transform(transactions)\n",
    "transaction_data = pd.DataFrame(onehot, columns=encoder.columns_)\n",
    "transaction_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6650a767",
   "metadata": {},
   "source": "## Step 4: Generate frequent `itemsets` using the Apriori algorithm"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. **Apriori Algorithm Application**\n",
    "    - Function: `apriori()`\n",
    "    - Parameters:\n",
    "        - `transaction_data`: Binary encoded transaction matrix\n",
    "        - `min_support=0.02`: Minimum support threshold (2%)\n",
    "        - `use_colnames=True`: Use item names instead of indices\n",
    "\n",
    "2. **Support Threshold**\n",
    "    - Support(itemset X) = (number of transactions containing itemset X) / (total transactions)\n",
    "    - 0.02 means itemset X must appear in at least 2% of transactions\n",
    "    - Helps filter out rare combinations\n",
    "\n",
    "3. **Result Generation**\n",
    "    - Creates a DataFrame containing:\n",
    "        - `itemsets`: Combinations of items\n",
    "        - `support`: Frequency of occurrence\n",
    "\n",
    "4. **Result Processing**\n",
    "    - `sort_values(by='support', ascending=False)`: Orders by support value (highest first)\n",
    "    - `head(10)`: Shows top 10 most frequent itemsets"
   ],
   "id": "200d6dd2edc69577"
  },
  {
   "cell_type": "code",
   "id": "d50fea9b",
   "metadata": {},
   "source": [
    "frequent_itemsets = apriori(transaction_data, min_support=0.02, use_colnames=True)\n",
    "frequent_itemsets.sort_values(by='support', ascending=False).head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "de5afbbb",
   "metadata": {},
   "source": "## Step 5: Generate and display the association rules"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. **Rules Generation**\n",
    "    - Function: `association_rules()`\n",
    "    - Input: `frequent_itemsets` from Apriori algorithm\n",
    "    - Parameters:\n",
    "        - `metric='lift'`: A measure of how much more often items in the antecedent and the items in the consequent appear together in transactions compared to what would be expected if they were statistically independent.\n",
    "        - `min_threshold=1.0`: Minimum lift value to include\n",
    "\n",
    "2. **Rules and Key Metrics**\n",
    "    - `antecedents`: \"If\" part of the rule (items in a basket)\n",
    "    - `consequents`: \"Then\" part of the rule (likely additional items)\n",
    "    - `support`: Frequency of items appearing together\n",
    "    - `confidence`: Probability of consequent given antecedent\n",
    "    - `lift`: Ratio of observed support to expected support\n",
    "\n",
    "3. **Sorting and Display**\n",
    "    - Sorts rules by confidence (highest first)\n",
    "    - Shows the top 10 strongest associations\n",
    "    - Displays most relevant columns for analysis"
   ],
   "id": "f24277983ab5546c"
  },
  {
   "cell_type": "code",
   "id": "d735dc2f",
   "metadata": {},
   "source": "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1.0)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Display the top 10 rules sorted by confidence",
   "id": "1c61bdf5fbc1ef5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rules = rules.sort_values(by='confidence', ascending=False)\n",
    "rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10)"
   ],
   "id": "fdf94effdae3dbaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Display the top 10 rules sorted by lift and then confidence",
   "id": "43f10e589b3b2b3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rules = rules.sort_values(by=['lift', 'confidence'], ascending=[False, False])\n",
    "rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10)"
   ],
   "id": "1721289096fd4c9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Filter the rules to show only those with high confidence and high lift",
   "id": "88c862e8146d424"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "strong_rules = rules[\n",
    "    (rules['confidence'] >= 0.8) &\n",
    "    (rules['lift'] >= 1.2)\n",
    "].sort_values(by='confidence', ascending=False)\n",
    "strong_rules.head(15)[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ],
   "id": "2f3ab6ccaa72e9fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 6: Remove duplicate and redundant rules",
   "id": "623a1d07420fb045"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter out redundant rules where antecedents are subsets of other antecedents\n",
    "def remove_duplicates(rules_df):\n",
    "    rules_df = rules_df.sort_values(by=['lift', 'confidence'], ascending=[False, False]).reset_index(drop=True)\n",
    "    unique_rules = []\n",
    "\n",
    "    for i, row_i in rules_df.iterrows():\n",
    "        is_redundant = False\n",
    "        for j, row_j in enumerate(unique_rules):\n",
    "            if row_i['consequents'] == row_j['consequents'] and row_i['antecedents'].issubset(row_j['antecedents']):\n",
    "                is_redundant = True\n",
    "                break\n",
    "\n",
    "        # Keep only non-redundant rules\n",
    "        if not is_redundant:\n",
    "            unique_rules.append(row_i)\n",
    "\n",
    "    return pd.DataFrame(unique_rules)\n",
    "\n",
    "# Apply the function to the strong rules\n",
    "nonredundant_rules = remove_duplicates(strong_rules)\n",
    "nonredundant_rules = nonredundant_rules.sort_values(by=['lift', 'support'], ascending=[False, False])\n",
    "nonredundant_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ],
   "id": "549e6e65fb614ce4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Eliminate bidirectional redundancy in rules\n",
    "def remove_bidirectional_redundancy(rules_df):\n",
    "    # Create a set to track unique antecedent-consequent pairs\n",
    "    seen_rules = set()\n",
    "    filtered_rules = []  # Store the final filtered rules\n",
    "\n",
    "    for _, row in rules_df.iterrows():\n",
    "        # Combine antecedents and consequents into a frozenset so the order doesn't matter\n",
    "        rule_pair = frozenset([frozenset(row['antecedents']), frozenset(row['consequents'])])\n",
    "\n",
    "        # Only keep the rule if it hasn't already been seen\n",
    "        if rule_pair not in seen_rules:\n",
    "            seen_rules.add(rule_pair)\n",
    "            filtered_rules.append(row)\n",
    "\n",
    "    return pd.DataFrame(filtered_rules)\n",
    "\n",
    "# Apply the function to the strong rules\n",
    "cleaned_rules = remove_bidirectional_redundancy(nonredundant_rules)\n",
    "cleaned_rules = cleaned_rules.sort_values(by=['lift', 'support'], ascending=[False, False])\n",
    "cleaned_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ],
   "id": "1dda0f79b2902b89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**List of Rules**",
   "id": "e5358444139cbb40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cleaned_rules = cleaned_rules.sort_values(by=['lift', 'confidence'], ascending=[False, False])\n",
    "cleaned_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10)"
   ],
   "id": "7c54074877e4982c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 7: Save the rules as a CSV file",
   "id": "64fbbb1f2fac909e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the output path\n",
    "output_path = './rule/top_rules_7a.csv'\n",
    "\n",
    "# Ensure the data directory exists\n",
    "if not os.path.exists('./rule'):\n",
    "    os.makedirs('./rule')\n",
    "\n",
    "# Save the top rules as a CSV file\n",
    "cleaned_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10).to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Top rules saved to {output_path}\")\n",
    "\n",
    "# Provide a download link if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(output_path)\n",
    "except ImportError:\n",
    "    print(\"❌ Not running in Google Colab, skipped rule download link.\")"
   ],
   "id": "486e7c7ad13b37bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 7: Visualize rules",
   "id": "58c13c64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(data=rules, x='support', y='confidence', size='lift', hue='lift', palette='viridis', sizes=(30, 300))\n",
    "plt.title('Support vs Confidence of Association Rules')\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Confidence')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Lift', bbox_to_anchor=(1.15, 1), loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6952eb68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(data=rules, x='lift', y='confidence', size='lift', hue='lift', palette='viridis', sizes=(30, 300))\n",
    "plt.title('Lift vs Confidence of Association Rules')\n",
    "plt.xlabel('Lift')\n",
    "plt.ylabel('Confidence')\n",
    "plt.grid(True)\n",
    "plt.legend(title='Lift', bbox_to_anchor=(1.15, 1), loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "88c9739afbf62601",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 8: Utilize the Rules",
   "id": "18c520f708297b02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Association rule mining is a **descriptive analysis** technique used to uncover useful associations/relationships in the data.\n",
    "- Once the associations/relationships have been uncovered, they can be used to inform business decisions such as:\n",
    "    - **Product Placement**: Place frequently bought together items near each other in stores.\n",
    "    - **Promotions**: Create promotions for items that are often purchased together.\n",
    "    - **Website Layout**: Design website sections to highlight complementary products.\n",
    "    - **Cross-Selling**: Train staff to suggest related products during customer interactions.\n",
    "    - **Inventory Management**: Stock items that are frequently bought together to reduce stockouts.\n",
    "    - **Personalized Recommendations**: Use rules to recommend products based on the items that the customer is about to purchase.\n",
    "- The following chunks present two of the ways in which a business can use the rules in existing information systems."
   ],
   "id": "312b92c6f71f7a5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Use Rules in a Traditional Programming Context (e.g., `if` Statements)\n",
    "If the rules generated are straightforward and few, they can be implemented using traditional programming constructs, such as `if` statements. These rules can then be operationalized for specific use cases such as:\n",
    "- Recommending items based on user transactions\n",
    "- Designing a system that triggers alerts or actions when conditions are met\n",
    "\n",
    "This approach is straightforward but **manual and static**, especially for larger datasets. If the rules change frequently (to adapt to changing consumer preferences), manually updating them in the code can be challenging."
   ],
   "id": "a7bc65052d650058"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def recommend_items(cart):\n",
    "    if {'sukuma wiki', 'matoke'}.issubset(cart):\n",
    "        return 'kienyeji chicken'\n",
    "    elif {'matoke', 'kienyeji chicken'}.issubset(cart):\n",
    "        return 'sukuma wiki'\n",
    "    elif {'maziwa mala'}.issubset(cart):\n",
    "        return 'beans'\n",
    "    else:\n",
    "        return 'No specific recommendation'\n",
    "\n",
    "# Example usage:\n",
    "customer_cart = {'maziwa mala', 'matoke', 'sukuma wiki'}\n",
    "recommendation = recommend_items(customer_cart)\n",
    "print(f\"Customer's shopping cart contains: {customer_cart}\")\n",
    "print(f\"Recommended item(s): {recommendation}\")"
   ],
   "id": "edd2548eceb950ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Integrate with a Rule-Based System\n",
    "An alternative is to store the rules dynamically in a database or as part of a rule engine. This allows:\n",
    "- Rules to be updated without modifying the code\n",
    "- Easier rule management for scalable use\n",
    "\n",
    "- The `if` statements implementation only returns the consequents of the first matching rule and then exits. It does not identify or aggregate all possible consequents for all matching rules.\n",
    "- A better alternative is to loop through all rules and check if the antecedents are present in the customer's cart. If they are, the consequents can be added to a list of recommendations."
   ],
   "id": "29a7fd047d3e71ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rules = [\n",
    "    {'antecedents': {'sukuma wiki', 'matoke'}, 'consequents': {'kienyeji chicken'}},\n",
    "    {'antecedents': {'matoke', 'kienyeji chicken'}, 'consequents': {'sukuma wiki'}},\n",
    "    {'antecedents': {'maziwa mala'}, 'consequents': {'beans'}},\n",
    "    {'antecedents': {'matoke', 'beans'}, 'consequents': {'maziwa mala'}},\n",
    "    {'antecedents': {'matoke', 'maziwa mala'}, 'consequents': {'beans'}},\n",
    "    {'antecedents': {'mango'}, 'consequents': {'beans'}},\n",
    "    {'antecedents': {'beans', 'mango'}, 'consequents': {'maziwa mala'}},\n",
    "    {'antecedents': {'mango'}, 'consequents': {'matoke', 'beans'}},\n",
    "    {'antecedents': {'ndizi'}, 'consequents': {'maziwa mala'}},\n",
    "    {'antecedents': {'matoke', 'mango'}, 'consequents': {'beans'}}\n",
    "]"
   ],
   "id": "7a8082ab4c0b292c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def dynamic_recommender(cart, rules_df):\n",
    "    recommendations = set()\n",
    "    for rule in rules_df:\n",
    "        if rule['antecedents'].issubset(cart):\n",
    "            recommendations.update(rule['consequents']) # Add consequents to recommendations\n",
    "    # Remove items already in the cart from recommendations\n",
    "    recommendations.difference_update(cart)\n",
    "    return list(recommendations) if recommendations else 'No recommendation'\n",
    "\n",
    "# Example usage:\n",
    "customer_cart = {'matoke', 'sukuma wiki', 'maziwa mala'}\n",
    "recommendation = dynamic_recommender(customer_cart, rules)\n",
    "print(f\"Customer's shopping cart contains: {customer_cart}\")\n",
    "print(f\"Recommended item(s): {recommendation}\")"
   ],
   "id": "f53e11f545eae0a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- An alternative to hardcoding the rules is to use the cleaned rules DataFrame created earlier or loaded from the CSV file.\n",
    "- This allows for easier updates and management of rules, especially as the dataset grows or changes."
   ],
   "id": "6ef4e6af2c391b10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def parse_frozenset(s):\n",
    "    # Extract the set part from \"frozenset({...})\"\n",
    "    match = re.match(r\"frozenset\\((.*)\\)\", s)\n",
    "    if match:\n",
    "        set_str = match.group(1)\n",
    "        return frozenset(ast.literal_eval(set_str))\n",
    "    else:\n",
    "        # Fallback: try to parse as a set directly\n",
    "        return frozenset(ast.literal_eval(s))\n",
    "\n",
    "# Load the rules from CSV\n",
    "cleaned_rules = pd.read_csv('./rule/top_rules_7a.csv')\n",
    "\n",
    "# Parse the antecedents and consequents columns\n",
    "cleaned_rules['antecedents'] = cleaned_rules['antecedents'].apply(parse_frozenset)\n",
    "cleaned_rules['consequents'] = cleaned_rules['consequents'].apply(parse_frozenset)"
   ],
   "id": "a2bc262911431762",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def dynamic_recommender(cart, rules_df):\n",
    "    recommendations = set()\n",
    "\n",
    "    for _, rule in rules_df.iterrows():\n",
    "        if rule['antecedents'].issubset(cart):\n",
    "            recommendations.update(rule['consequents']) # Add consequents to recommendations\n",
    "    # Remove items already in the cart from recommendations\n",
    "    recommendations.difference_update(cart)\n",
    "    return list(recommendations)\n",
    "\n",
    "customer_cart = {'matoke', 'maziwa mala', 'sukuma wiki'}\n",
    "recommended_items = dynamic_recommender(customer_cart, cleaned_rules)\n",
    "print(f\"Customer's shopping cart contains: {customer_cart}\")\n",
    "print(f\"Recommended items: {recommended_items}\")"
   ],
   "id": "10d16846be35271c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 9: Business Analysis\n",
    "- `sukuma wiki`, `matoke`, and `kienyeji chicken` are frequently bought together.\n",
    "- `maziwa mala` and `beans` are also frequently bought together.\n",
    "- The business can use this to:\n",
    "    - Place these items near each other in the store.\n",
    "    - Create promotions that bundle these items together.\n",
    "    - Train the staff to suggest these items when customers purchase one of them.\n",
    "- The rules can be integrated into the store's POS system to provide real-time recommendations to cashiers or customers.\n",
    "- The business can also analyze the rules to identify potential gaps in their product offerings or to optimize inventory management.\n",
    "- Overall, the insights from association rule learning can help the business improve customer satisfaction, increase sales, and optimize operations.\n",
    "- The business should continuously monitor and update the rules as customer preferences and purchasing behaviors evolve over time.\n",
    "- This can be done by periodically re-running the Apriori algorithm on new transaction data. This ensures that the business stays relevant and responsive to market trends."
   ],
   "id": "ae6bdddd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "Hahsler, M., Chelluboina, S., Hornik, K., & Buchta, C. (2011). The arules R-Package Ecosystem: Analyzing Interesting Patterns from Large Transaction Datasets. Journal of Machine Learning Research, 12, 1977–1981.\n"
   ],
   "id": "2c0a87e3056f186b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
